{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf45db1",
   "metadata": {},
   "source": [
    "# FGSD Experiment on IMDB-MULTI\n",
    "This notebook runs the Flexible FGSD and Hybrid FGSD experiments on the IMDB-MULTI dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf23c45",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7a8e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added to path: /home/stavros/emb3/fgsd_method/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "print(f\"✅ Added to path: {parent_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7be5415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stavros/miniconda3/envs/graphs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import tracemalloc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import networkx as nx\n",
    "from karateclub.estimator import Estimator\n",
    "import warnings\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "sys.path.append(\".\")\n",
    "from fgsd import FlexibleFGSD\n",
    "from optimized_method import HybridFGSD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32519ab",
   "metadata": {},
   "source": [
    "## Download and Load IMDB-MULTI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879ecea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_load_imdb():\n",
    "    data_dir = '/tmp/IMDB-MULTI'\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    base_url = 'https://www.chrsmrrs.com/graphkerneldatasets/IMDB-MULTI.zip'\n",
    "    zip_path = os.path.join(data_dir, 'IMDB-MULTI.zip')\n",
    "\n",
    "    if not os.path.exists(os.path.join(data_dir, 'IMDB-MULTI')):\n",
    "        print(\"Downloading IMDB-MULTI dataset...\")\n",
    "        urllib.request.urlretrieve(base_url, zip_path)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)\n",
    "        print(\"Download complete.\")\n",
    "\n",
    "    dataset_path = os.path.join(data_dir, 'IMDB-MULTI')\n",
    "\n",
    "    graph_indicator = np.loadtxt(os.path.join(dataset_path, 'IMDB-MULTI_graph_indicator.txt'), dtype=int)\n",
    "    edges = np.loadtxt(os.path.join(dataset_path, 'IMDB-MULTI_A.txt'), dtype=int, delimiter=',')\n",
    "    graph_labels = np.loadtxt(os.path.join(dataset_path, 'IMDB-MULTI_graph_labels.txt'), dtype=int)\n",
    "    \n",
    "    # IMDB-MULTI does not have node labels\n",
    "\n",
    "    num_graphs = len(graph_labels)\n",
    "    graphs = [nx.Graph() for _ in range(num_graphs)]\n",
    "\n",
    "    for node_id, graph_id in enumerate(graph_indicator, start=1):\n",
    "        graphs[graph_id - 1].add_node(node_id)\n",
    "\n",
    "    for node1, node2 in edges:\n",
    "        graph_id = graph_indicator[node1 - 1]\n",
    "        graphs[graph_id - 1].add_edge(node1, node2)\n",
    "\n",
    "    graphs = [nx.convert_node_labels_to_integers(g) for g in graphs]\n",
    "    labels = graph_labels - 1\n",
    "\n",
    "    return graphs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33995cf",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0812356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_classifier(X_train, X_test, y_train, y_test, classifier_name, clf):\n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    start_time = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    try:\n",
    "        y_test_bin = label_binarize(y_test, classes=np.unique(y_train))\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            y_score = clf.predict_proba(X_test)\n",
    "        elif hasattr(clf, 'decision_function'):\n",
    "            y_score = clf.decision_function(X_test)\n",
    "            if len(y_score.shape) == 1:\n",
    "                y_score = y_score.reshape(-1, 1)\n",
    "        else:\n",
    "            y_score = None\n",
    "\n",
    "        if y_score is not None and y_test_bin.shape[1] > 1:\n",
    "            auc = roc_auc_score(y_test_bin, y_score, average='weighted', multi_class='ovr')\n",
    "        else:\n",
    "            auc = None\n",
    "    except:\n",
    "        auc = None\n",
    "\n",
    "    return {\n",
    "        'classifier': classifier_name,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'auc': auc,\n",
    "        'train_time': train_time,\n",
    "        'inference_time': inference_time\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf1b255",
   "metadata": {},
   "source": [
    "## Run FGSD Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6886b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(configs, test_size=0.15, random_state=42):\n",
    "    print(\"Loading IMDB-MULTI dataset...\")\n",
    "    graphs, labels = download_and_load_imdb()\n",
    "\n",
    "    print(\"IMDB-MULTI has no node labels. Using only spectral features.\")\n",
    "\n",
    "    graphs_train, graphs_test, y_train, y_test = train_test_split(\n",
    "        graphs, labels, test_size=test_size, random_state=random_state, stratify=labels\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, config in enumerate(configs):\n",
    "        func = config['func']\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        if func == 'hybrid':\n",
    "            harm_bins = config.get('harm_bins', 200)\n",
    "            harm_range = config.get('harm_range', 20)\n",
    "            pol_bins = config.get('pol_bins', 70)\n",
    "            pol_range = config.get('pol_range', 4.1)\n",
    "            print(f\"Experiment {i+1}/{len(configs)}: Function='{func}'\")\n",
    "        else:\n",
    "            bins = config['bins']\n",
    "            rng = config['range']\n",
    "            print(f\"Experiment {i+1}/{len(configs)}: Function='{func}', Bins={bins}, Range={rng}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        tracemalloc.start()\n",
    "        start_time = time.time()\n",
    "\n",
    "        if func == 'hybrid':\n",
    "            model = HybridFGSD(\n",
    "                harm_bins=harm_bins, harm_range=harm_range,\n",
    "                pol_bins=pol_bins, pol_range=pol_range,\n",
    "                func_type='hybrid', seed=random_state\n",
    "            )\n",
    "        else:\n",
    "            model = FlexibleFGSD(hist_bins=bins, hist_range=rng, func_type=func, seed=random_state)\n",
    "\n",
    "        model.fit(graphs_train)\n",
    "        X_train = model.get_embedding()\n",
    "        X_test = model.infer(graphs_test)\n",
    "\n",
    "        generation_time = time.time() - start_time\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "\n",
    "        print(f\"Embedding Shape: {X_train.shape}\")\n",
    "\n",
    "        classifiers = {\n",
    "            'SVM (RBF) + Scaler': make_pipeline(\n",
    "                StandardScaler(),\n",
    "                SVC(kernel='rbf', C=500, gamma='scale', probability=True, random_state=random_state)\n",
    "            ),\n",
    "            'Random Forest': RandomForestClassifier(n_estimators=3000, random_state=random_state),\n",
    "            'MLP': make_pipeline(\n",
    "                StandardScaler(), \n",
    "                MLPClassifier(\n",
    "                    hidden_layer_sizes=(1024, 512, 256, 128), \n",
    "                    activation='relu',\n",
    "                    solver='adam',\n",
    "                    alpha=0.001,\n",
    "                    learning_rate_init=0.001,\n",
    "                    learning_rate='adaptive',\n",
    "                    max_iter=2000, \n",
    "                    early_stopping=True,      \n",
    "                    n_iter_no_change=20,      \n",
    "                    random_state=random_state\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            res = evaluate_classifier(X_train, X_test, y_train, y_test, clf_name, clf)\n",
    "            res.update(config)\n",
    "            res['generation_time'] = generation_time\n",
    "            results.append(res)\n",
    "            print(f\"  -> {clf_name}: Train Acc={res['train_accuracy']:.4f}, Test Acc={res['accuracy']:.4f}, F1={res['f1_score']:.4f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838424d",
   "metadata": {},
   "source": [
    "## Summary Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c997ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_summary(results):\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"SUMMARY OF RESULTS\")\n",
    "    print(\"=\"*120)\n",
    "    print(f\"{'Func':<12} {'Parameters':<30} {'Classifier':<20} {'Train Acc':<11} {'Test Acc':<10} {'F1':<10} {'GenTime':<8}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda x: x['accuracy'], reverse=True)\n",
    "\n",
    "    for r in sorted_results:\n",
    "        if r['func'] == 'hybrid':\n",
    "            params = f\"h_bins={r.get('harm_bins')},h_range={r.get('harm_range')},p_bins={r.get('pol_bins')},p_range={r.get('pol_range')}\"\n",
    "        else:\n",
    "            params = f\"bins={r.get('bins')}, range={r.get('range')}\"\n",
    "\n",
    "        print(f\"{r['func']:<12} {params:<30} {r['classifier']:<20} \"\n",
    "              f\"{r['train_accuracy']:<11.4f} {r['accuracy']:<10.4f} {r['f1_score']:<10.4f} {r['generation_time']:<8.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e58d7fb",
   "metadata": {},
   "source": [
    "## Run the Full Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba1a275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Multi-Configuration FGSD Experiment on IMDB-MULTI...\n",
      "Loading IMDB-MULTI dataset...\n",
      "IMDB-MULTI has no node labels. Using only spectral features.\n",
      "\n",
      "================================================================================\n",
      "Experiment 1/3: Function='hybrid'\n",
      "================================================================================\n",
      "Embedding Shape: (1275, 300)\n",
      "  -> SVM (RBF) + Scaler: Train Acc=0.6486, Test Acc=0.4489, F1=0.4403\n",
      "  -> Random Forest: Train Acc=0.6541, Test Acc=0.4756, F1=0.4607\n",
      "  -> MLP: Train Acc=0.6212, Test Acc=0.4667, F1=0.4464\n",
      "\n",
      "================================================================================\n",
      "Experiment 2/3: Function='polynomial', Bins=200, Range=3.1\n",
      "================================================================================\n",
      "Embedding Shape: (1275, 200)\n",
      "  -> SVM (RBF) + Scaler: Train Acc=0.6376, Test Acc=0.4844, F1=0.4724\n",
      "  -> Random Forest: Train Acc=0.6376, Test Acc=0.4978, F1=0.4841\n",
      "  -> MLP: Train Acc=0.5584, Test Acc=0.4222, F1=0.4237\n",
      "\n",
      "================================================================================\n",
      "Experiment 3/3: Function='harmonic', Bins=100, Range=3.5\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stavros/emb3/fgsd_method/src/fgsd.py:33: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  func_w = np.where(w > 1e-9, 1.0 / w, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shape: (1275, 100)\n",
      "  -> SVM (RBF) + Scaler: Train Acc=0.6384, Test Acc=0.4756, F1=0.4624\n",
      "  -> Random Forest: Train Acc=0.6525, Test Acc=0.4756, F1=0.4605\n",
      "  -> MLP: Train Acc=0.6275, Test Acc=0.4800, F1=0.4575\n",
      "\n",
      "========================================================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "========================================================================================================================\n",
      "Func         Parameters                     Classifier           Train Acc   Test Acc   F1         GenTime \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "polynomial   bins=200, range=3.1            Random Forest        0.6376      0.4978     0.4841     10.40   \n",
      "polynomial   bins=200, range=3.1            SVM (RBF) + Scaler   0.6376      0.4844     0.4724     10.40   \n",
      "harmonic     bins=100, range=3.5            MLP                  0.6275      0.4800     0.4575     9.51    \n",
      "hybrid       h_bins=100,h_range=3.5,p_bins=200,p_range=3.5 Random Forest        0.6541      0.4756     0.4607     8.91    \n",
      "harmonic     bins=100, range=3.5            SVM (RBF) + Scaler   0.6384      0.4756     0.4624     9.51    \n",
      "harmonic     bins=100, range=3.5            Random Forest        0.6525      0.4756     0.4605     9.51    \n",
      "hybrid       h_bins=100,h_range=3.5,p_bins=200,p_range=3.5 MLP                  0.6212      0.4667     0.4464     8.91    \n",
      "hybrid       h_bins=100,h_range=3.5,p_bins=200,p_range=3.5 SVM (RBF) + Scaler   0.6486      0.4489     0.4403     8.91    \n",
      "polynomial   bins=200, range=3.1            MLP                  0.5584      0.4222     0.4237     10.40   \n"
     ]
    }
   ],
   "source": [
    "configs = [\n",
    "    {'func': 'hybrid', 'harm_bins': 100, 'harm_range': 3.5, 'pol_bins': 200, 'pol_range': 3.5},\n",
    "    {'func': 'polynomial', 'bins': 200, 'range': 3.1},\n",
    "    {'func': 'harmonic', 'bins': 100, 'range': 3.5},\n",
    "]\n",
    "\n",
    "print(\"Starting Multi-Configuration FGSD Experiment on IMDB-MULTI...\")\n",
    "results = run_experiment(configs)\n",
    "print_summary(results)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"fgsd_imdb_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
