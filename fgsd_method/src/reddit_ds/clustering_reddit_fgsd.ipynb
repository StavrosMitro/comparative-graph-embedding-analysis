{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f5bd63",
   "metadata": {},
   "source": [
    "# FGSD Clustering Experiment on REDDIT-MULTI-12K\n",
    "This notebook runs Unsupervised Clustering (K-Means, Spectral Clustering) on the REDDIT-MULTI-12K dataset using FGSD embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b75bb5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "print(f\"Added to path: {parent_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd68da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import warnings\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize \n",
    "\n",
    "try:\n",
    "    import umap\n",
    "    HAS_UMAP = True\n",
    "except ImportError:\n",
    "    print(\"Warning: 'umap-learn' not found. Visualization will only use t-SNE.\")\n",
    "    HAS_UMAP = False\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43adbdf2",
   "metadata": {},
   "source": [
    "# Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we can import from src\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from optimized_method import HybridFGSD \n",
    "from fgsd import FlexibleFGSD \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c9360",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_load_reddit():\n",
    "    data_dir = '/tmp/REDDIT-MULTI-12K'\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    base_url = 'https://www.chrsmrrs.com/graphkerneldatasets/REDDIT-MULTI-12K.zip'\n",
    "    zip_path = os.path.join(data_dir, 'REDDIT-MULTI-12K.zip')\n",
    "\n",
    "    if not os.path.exists(os.path.join(data_dir, 'REDDIT-MULTI-12K')):\n",
    "        print(\"Downloading REDDIT-MULTI-12K dataset...\")\n",
    "        urllib.request.urlretrieve(base_url, zip_path)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)\n",
    "        print(\"Download complete.\")\n",
    "\n",
    "    dataset_path = os.path.join(data_dir, 'REDDIT-MULTI-12K')\n",
    "\n",
    "    graph_indicator = np.loadtxt(os.path.join(dataset_path, 'REDDIT-MULTI-12K_graph_indicator.txt'), dtype=int)\n",
    "    edges = np.loadtxt(os.path.join(dataset_path, 'REDDIT-MULTI-12K_A.txt'), dtype=int, delimiter=',')\n",
    "    graph_labels = np.loadtxt(os.path.join(dataset_path, 'REDDIT-MULTI-12K_graph_labels.txt'), dtype=int)\n",
    "    \n",
    "    # REDDIT-MULTI-12K does not have node labels\n",
    "\n",
    "    num_graphs = len(graph_labels)\n",
    "    graphs = [nx.Graph() for _ in range(num_graphs)]\n",
    "\n",
    "    for node_id, graph_id in enumerate(graph_indicator, start=1):\n",
    "        graphs[graph_id - 1].add_node(node_id)\n",
    "\n",
    "    for node1, node2 in edges:\n",
    "        graph_id = graph_indicator[node1 - 1]\n",
    "        graphs[graph_id - 1].add_edge(node1, node2)\n",
    "\n",
    "    graphs = [nx.convert_node_labels_to_integers(g) for g in graphs]\n",
    "    labels = graph_labels - 1\n",
    "\n",
    "    return graphs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e883b6a0",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9154d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(graphs, config):\n",
    "    \"\"\"\n",
    "    Generates Spectral features for REDDIT-MULTI-12K.\n",
    "    \"\"\"\n",
    "    func = config['func']\n",
    "    if func == 'hybrid':\n",
    "        model = HybridFGSD(\n",
    "            harm_bins=config['harm_bins'], \n",
    "            harm_range=config['harm_range'],\n",
    "            pol_bins=config['pol_bins'], \n",
    "            pol_range=config['pol_range'],\n",
    "            func_type='hybrid', \n",
    "            seed=42)\n",
    "    else:\n",
    "        model = FlexibleFGSD(\n",
    "            hist_bins=config['bins'], \n",
    "            hist_range=config['range'], \n",
    "            func_type=func, \n",
    "            seed=42)\n",
    "            \n",
    "    model.fit(graphs)\n",
    "    X_spectral = model.get_embedding()\n",
    "    \n",
    "    # Normalize spectral features\n",
    "    scaler_spec = StandardScaler()\n",
    "    X_spectral_norm = scaler_spec.fit_transform(X_spectral)\n",
    "    \n",
    "    return X_spectral_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1de437",
   "metadata": {},
   "source": [
    "# Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering_analysis(X, y_true, n_neighbors=50):\n",
    "    # scaler = StandardScaler()\n",
    "    # X_std = scaler.fit_transform(X)\n",
    "    X_norm = normalize(X, norm='l2')\n",
    "    pca = PCA(n_components=0.95, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_norm)\n",
    "    n_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # K-Means Hyperparameters:\n",
    "    kmeans = KMeans(n_clusters=n_classes, random_state=42, n_init=50)\n",
    "    y_kmeans = kmeans.fit_predict(X_pca)\n",
    "    \n",
    "    # Spectral Clustering Hyperparameters:\n",
    "    spectral = SpectralClustering(n_clusters=n_classes, affinity='nearest_neighbors', \n",
    "                                  n_neighbors=n_neighbors, assign_labels='discretize', \n",
    "                                  random_state=42, n_jobs=-1)\n",
    "    y_spectral = spectral.fit_predict(X_pca)\n",
    "    return X_pca, y_kmeans, y_spectral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea06eb",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(X_scaled, y_true, y_kmeans, y_spectral, config_name):\n",
    "    labels_list = [y_true, y_kmeans, y_spectral]\n",
    "    if HAS_UMAP:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        umap_row = axes[0]\n",
    "        tsne_row = axes[1]\n",
    "        reducer_umap = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "        embedding_umap = reducer_umap.fit_transform(X_scaled)\n",
    "        titles_umap = ['GT (UMAP)', 'KMeans (UMAP)', 'Spectral (UMAP)']\n",
    "        for ax, labels, title in zip(umap_row, labels_list, titles_umap):\n",
    "            ax.scatter(embedding_umap[:,0], embedding_umap[:,1], c=labels, cmap='tab10', s=15)\n",
    "            ax.set_title(title); ax.axis('off')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        tsne_row = axes\n",
    "    reducer_tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "    embedding_tsne = reducer_tsne.fit_transform(X_scaled)\n",
    "    titles_tsne = ['GT (t-SNE)', 'KMeans (t-SNE)', 'Spectral (t-SNE)']\n",
    "    for ax, labels, title in zip(tsne_row, labels_list, titles_tsne):\n",
    "        ax.scatter(embedding_tsne[:,0], embedding_tsne[:,1], c=labels, cmap='tab10', s=15)\n",
    "        ax.set_title(title); ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"clustering_reddit_{config_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d727f",
   "metadata": {},
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    {'name':'hybrid_100_3.5_200_3.5','func':'hybrid','harm_bins':100,'harm_range':3.5,'pol_bins':200,'pol_range':3.5},\n",
    "    {'name':'polynomial_200_3.1','func':'polynomial','bins':200,'range':3.1},\n",
    "    {'name':'harmonic_100_3.5','func':'harmonic','bins':100,'range':3.5},\n",
    "]\n",
    "\n",
    "# Hyperparameters to tune\n",
    "neighbor_values = [10, 20]\n",
    "\n",
    "print(\"Loading REDDIT-MULTI-12K Data...\")\n",
    "graphs, labels = download_and_load_reddit()\n",
    "\n",
    "for config in configurations:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing Configuration: {config['name']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    X = generate_embeddings(graphs, config)\n",
    "    \n",
    "    for n_neighbors in neighbor_values:\n",
    "        print(f\"\\n--- Tuning: n_neighbors={n_neighbors} ---\")\n",
    "        X_scaled, y_kmeans, y_spectral = perform_clustering_analysis(X, labels, n_neighbors=n_neighbors)\n",
    "        \n",
    "        km_ari = adjusted_rand_score(labels, y_kmeans)\n",
    "        km_sil = silhouette_score(X_scaled, y_kmeans)\n",
    "        \n",
    "        sp_ari = adjusted_rand_score(labels, y_spectral)\n",
    "        sp_sil = silhouette_score(X_scaled, y_spectral)\n",
    "        print(f\"K-Means  -> ARI: {km_ari:.4f} | Silhouette: {km_sil:.4f}\")\n",
    "        print(f\"Spectral -> ARI: {sp_ari:.4f} | Silhouette: {sp_sil:.4f}\")\n",
    "        \n",
    "        # Visualize only for the first neighbor setting to avoid clutter\n",
    "        if n_neighbors == 10:\n",
    "            print(\"Generating Visualization (n_neighbors=10)...\")\n",
    "            visualize_clusters(X_scaled, labels, y_kmeans, y_spectral, config['name'])\n",
    "            print(f\"Plots displayed above and saved to 'clustering_reddit_{config['name']}.png'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
