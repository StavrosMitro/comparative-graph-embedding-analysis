{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d8e6766",
   "metadata": {},
   "source": [
    "# FGSD Clustering Experiment on IMDB-MULTI\n",
    "This notebook runs Unsupervised Clustering (K-Means, Spectral Clustering) on the IMDB-MULTI dataset using FGSD embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7991f86",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa20018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to path: /home/stavros/emb3/fgsd_method/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "print(f\"Added to path: {parent_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3c56df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'umap-learn' not found. Visualization will only use t-SNE.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import warnings\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize \n",
    "\n",
    "try:\n",
    "    import umap\n",
    "    HAS_UMAP = True\n",
    "except ImportError:\n",
    "    print(\"Warning: 'umap-learn' not found. Visualization will only use t-SNE.\")\n",
    "    HAS_UMAP = False\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c913df1",
   "metadata": {},
   "source": [
    "# Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf18b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stavros/miniconda3/envs/graphs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Ensure we can import from src\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from optimized_method import HybridFGSD \n",
    "from fgsd import FlexibleFGSD \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03bd59d",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3a70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_load_imdb():\n",
    "    data_dir = '/tmp/IMDB-MULTI'\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    base_url = 'https://www.chrsmrrs.com/graphkerneldatasets/IMDB-MULTI.zip'\n",
    "    zip_path = os.path.join(data_dir, 'IMDB-MULTI.zip')\n",
    "\n",
    "    if not os.path.exists(os.path.join(data_dir, 'IMDB-MULTI')):\n",
    "        print(\"Downloading IMDB-MULTI dataset...\")\n",
    "        urllib.request.urlretrieve(base_url, zip_path)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)\n",
    "        print(\"Download complete.\")\n",
    "\n",
    "    dataset_path = os.path.join(data_dir, 'IMDB-MULTI')\n",
    "\n",
    "    graph_indicator = np.loadtxt(os.path.join(dataset_path, 'IMDB-MULTI_graph_indicator.txt'), dtype=int)\n",
    "    edges = np.loadtxt(os.path.join(dataset_path, 'IMDB-MULTI_A.txt'), dtype=int, delimiter=',')\n",
    "    graph_labels = np.loadtxt(os.path.join(dataset_path, 'IMDB-MULTI_graph_labels.txt'), dtype=int)\n",
    "    \n",
    "    # IMDB-MULTI does not have node labels\n",
    "\n",
    "    num_graphs = len(graph_labels)\n",
    "    graphs = [nx.Graph() for _ in range(num_graphs)]\n",
    "\n",
    "    for node_id, graph_id in enumerate(graph_indicator, start=1):\n",
    "        graphs[graph_id - 1].add_node(node_id)\n",
    "\n",
    "    for node1, node2 in edges:\n",
    "        graph_id = graph_indicator[node1 - 1]\n",
    "        graphs[graph_id - 1].add_edge(node1, node2)\n",
    "\n",
    "    graphs = [nx.convert_node_labels_to_integers(g) for g in graphs]\n",
    "    labels = graph_labels - 1\n",
    "\n",
    "    return graphs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5a703",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8bc4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(graphs, config):\n",
    "    \"\"\"\n",
    "    Generates Spectral features for IMDB-MULTI.\n",
    "    \"\"\"\n",
    "    func = config['func']\n",
    "    if func == 'hybrid':\n",
    "        model = HybridFGSD(\n",
    "            harm_bins=config['harm_bins'], \n",
    "            harm_range=config['harm_range'],\n",
    "            pol_bins=config['pol_bins'], \n",
    "            pol_range=config['pol_range'],\n",
    "            func_type='hybrid', \n",
    "            seed=42)\n",
    "    else:\n",
    "        model = FlexibleFGSD(\n",
    "            hist_bins=config['bins'], \n",
    "            hist_range=config['range'], \n",
    "            func_type=func, \n",
    "            seed=42)\n",
    "            \n",
    "    model.fit(graphs)\n",
    "    X_spectral = model.get_embedding()\n",
    "    \n",
    "    # Normalize spectral features\n",
    "    scaler_spec = StandardScaler()\n",
    "    X_spectral_norm = scaler_spec.fit_transform(X_spectral)\n",
    "    \n",
    "    return X_spectral_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ffefd3",
   "metadata": {},
   "source": [
    "# Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20ab8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering_analysis(X, y_true, n_neighbors=50):\n",
    "    # scaler = StandardScaler()\n",
    "    # X_std = scaler.fit_transform(X)\n",
    "    X_norm = normalize(X, norm='l2')\n",
    "    pca = PCA(n_components=0.95, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_norm)\n",
    "    n_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # K-Means Hyperparameters:\n",
    "    # n_init: Number of times the k-means algorithm will be run with different centroid seeds.\n",
    "    kmeans = KMeans(n_clusters=n_classes, random_state=42, n_init=50)\n",
    "    y_kmeans = kmeans.fit_predict(X_pca)\n",
    "    \n",
    "    # Spectral Clustering Hyperparameters:\n",
    "    # n_neighbors: Number of neighbors to use when constructing the affinity matrix.\n",
    "    # assign_labels: Strategy to assign labels in the embedding space ('kmeans' or 'discretize').\n",
    "    spectral = SpectralClustering(n_clusters=n_classes, affinity='nearest_neighbors', \n",
    "                                  n_neighbors=n_neighbors, assign_labels='discretize', \n",
    "                                  random_state=42, n_jobs=-1)\n",
    "    y_spectral = spectral.fit_predict(X_pca)\n",
    "    return X_pca, y_kmeans, y_spectral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fa3171",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a440e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(X_scaled, y_true, y_kmeans, y_spectral, config_name):\n",
    "    labels_list = [y_true, y_kmeans, y_spectral]\n",
    "    if HAS_UMAP:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        umap_row = axes[0]\n",
    "        tsne_row = axes[1]\n",
    "        reducer_umap = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "        embedding_umap = reducer_umap.fit_transform(X_scaled)\n",
    "        titles_umap = ['GT (UMAP)', 'KMeans (UMAP)', 'Spectral (UMAP)']\n",
    "        for ax, labels, title in zip(umap_row, labels_list, titles_umap):\n",
    "            ax.scatter(embedding_umap[:,0], embedding_umap[:,1], c=labels, cmap='tab10', s=15)\n",
    "            ax.set_title(title); ax.axis('off')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        tsne_row = axes\n",
    "    reducer_tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "    embedding_tsne = reducer_tsne.fit_transform(X_scaled)\n",
    "    titles_tsne = ['GT (t-SNE)', 'KMeans (t-SNE)', 'Spectral (t-SNE)']\n",
    "    for ax, labels, title in zip(tsne_row, labels_list, titles_tsne):\n",
    "        ax.scatter(embedding_tsne[:,0], embedding_tsne[:,1], c=labels, cmap='tab10', s=15)\n",
    "        ax.set_title(title); ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"clustering_imdb_{config_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e70eb0",
   "metadata": {},
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "626d67fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB-MULTI Data...\n",
      "\n",
      "================================================================================\n",
      "Processing Configuration: hybrid_100_3.5_200_3.5\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing Configuration: hybrid_100_3.5_200_3.5\n",
      "================================================================================\n",
      "\n",
      "--- Tuning: n_neighbors=50 ---\n",
      "\n",
      "--- Tuning: n_neighbors=50 ---\n",
      "K-Means  -> ARI: 0.0096 | Silhouette: 0.3309\n",
      "Spectral -> ARI: 0.0065 | Silhouette: 0.2963\n",
      "\n",
      "================================================================================\n",
      "Processing Configuration: polynomial_200_3.1\n",
      "================================================================================\n",
      "K-Means  -> ARI: 0.0096 | Silhouette: 0.3309\n",
      "Spectral -> ARI: 0.0065 | Silhouette: 0.2963\n",
      "\n",
      "================================================================================\n",
      "Processing Configuration: polynomial_200_3.1\n",
      "================================================================================\n",
      "\n",
      "--- Tuning: n_neighbors=50 ---\n",
      "\n",
      "--- Tuning: n_neighbors=50 ---\n",
      "K-Means  -> ARI: 0.0059 | Silhouette: 0.3373\n",
      "Spectral -> ARI: 0.0059 | Silhouette: 0.3367\n",
      "\n",
      "================================================================================\n",
      "Processing Configuration: harmonic_100_3.5\n",
      "================================================================================\n",
      "K-Means  -> ARI: 0.0059 | Silhouette: 0.3373\n",
      "Spectral -> ARI: 0.0059 | Silhouette: 0.3367\n",
      "\n",
      "================================================================================\n",
      "Processing Configuration: harmonic_100_3.5\n",
      "================================================================================\n",
      "\n",
      "--- Tuning: n_neighbors=50 ---\n",
      "\n",
      "--- Tuning: n_neighbors=50 ---\n",
      "K-Means  -> ARI: 0.0101 | Silhouette: 0.3458\n",
      "Spectral -> ARI: 0.0062 | Silhouette: 0.3296\n",
      "K-Means  -> ARI: 0.0101 | Silhouette: 0.3458\n",
      "Spectral -> ARI: 0.0062 | Silhouette: 0.3296\n"
     ]
    }
   ],
   "source": [
    "configurations = [\n",
    "    {'name':'hybrid_100_3.5_200_3.5','func':'hybrid','harm_bins':100,'harm_range':3.5,'pol_bins':200,'pol_range':3.5},\n",
    "    {'name':'polynomial_200_3.1','func':'polynomial','bins':200,'range':3.1},\n",
    "    {'name':'harmonic_100_3.5','func':'harmonic','bins':100,'range':3.5},\n",
    "]\n",
    "\n",
    "# Hyperparameters to tune\n",
    "neighbor_values = [10, 20]\n",
    "\n",
    "print(\"Loading IMDB-MULTI Data...\")\n",
    "graphs, labels = download_and_load_imdb()\n",
    "\n",
    "for config in configurations:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing Configuration: {config['name']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    X = generate_embeddings(graphs, config)\n",
    "    \n",
    "    for n_neighbors in neighbor_values:\n",
    "        print(f\"\\n--- Tuning: n_neighbors={n_neighbors} ---\")\n",
    "        X_scaled, y_kmeans, y_spectral = perform_clustering_analysis(X, labels, n_neighbors=n_neighbors)\n",
    "        \n",
    "        km_ari = adjusted_rand_score(labels, y_kmeans)\n",
    "        km_sil = silhouette_score(X_scaled, y_kmeans)\n",
    "        \n",
    "        sp_ari = adjusted_rand_score(labels, y_spectral)\n",
    "        sp_sil = silhouette_score(X_scaled, y_spectral)\n",
    "        print(f\"K-Means  -> ARI: {km_ari:.4f} | Silhouette: {km_sil:.4f}\")\n",
    "        print(f\"Spectral -> ARI: {sp_ari:.4f} | Silhouette: {sp_sil:.4f}\")\n",
    "        \n",
    "        # Visualize only for the first neighbor setting to avoid clutter\n",
    "        if n_neighbors == 10:\n",
    "            print(\"Generating Visualization (n_neighbors=10)...\")\n",
    "            visualize_clusters(X_scaled, labels, y_kmeans, y_spectral, config['name'])\n",
    "            print(f\"Plots displayed above and saved to 'clustering_imdb_{config['name']}.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
